import sys
import os
import glob
import torch
import time
import warnings # [æ–°å¢]


# --- è·¯å¾„é…ç½® ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from monai.losses import DiceCELoss
from monai.metrics import DiceMetric
from monai.inferers import sliding_window_inference
from monai.utils import set_determinism
from monai.data import decollate_batch, partition_dataset
from monai.transforms import AsDiscrete

# å¯¼å…¥ä½ çš„æ¨¡å—
from src.models.unet3D import UNet3D
from src.dataloaders.basic_loader import get_basic_loader

def train_baseline():
    # ================= é…ç½®åŒºåŸŸ =================
    # è·¯å¾„é…ç½®
    DATA_DIR = "/home/lzf/Code/dataset/nnUNet_raw/Dataset701_STS3D_ROI"  # ä½ çš„ ROI æ•°æ®è·¯å¾„
    MODEL_SAVE_DIR = "./models"
    os.makedirs(MODEL_SAVE_DIR, exist_ok=True)
    
    # è®­ç»ƒè¶…å‚æ•°
    MAX_EPOCHS = 100
    VAL_INTERVAL = 2        # æ¯å¤šå°‘ä¸ª epoch éªŒè¯ä¸€æ¬¡
    BATCH_SIZE = 2
    LR = 1e-4
    ROI_SIZE = (96, 96, 96) # Patch å¤§å°
    
    # æ˜¾å­˜/å†…å­˜ä¼˜åŒ–é…ç½®
    AMP = True              # å¼€å¯æ··åˆç²¾åº¦
    NUM_WORKERS = 2         # WSLå»ºè®®è®¾ä¸º2æˆ–0
    CACHE_RATE = 0.0        # è®¾ä¸º0.0é˜²æ­¢å†…å­˜æº¢å‡º
    
    # ================= 1. æ•°æ®å‡†å¤‡ =================
    set_determinism(seed=2025) 
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    print("æ­£åœ¨æ‰«æå¹¶åˆ’åˆ†æ•°æ®é›†...")
    images = sorted(glob.glob(os.path.join(DATA_DIR, "imagesTr", "*.nii.gz")))
    labels = sorted(glob.glob(os.path.join(DATA_DIR, "labelsTr", "*.nii.gz")))
    
    if not images:
        raise ValueError(f"é”™è¯¯ï¼šåœ¨ {DATA_DIR} ä¸­æœªæ‰¾åˆ°æ•°æ®ï¼")
        
    data_dicts = [{"image": img, "label": lbl} for img, lbl in zip(images, labels)]
    
    train_files, val_files = partition_dataset(
        data=data_dicts, 
        ratios=[0.8, 0.2], 
        shuffle=True, 
        seed=2025
    )
    
    print(f"  - æ€»æ•°æ®é‡: {len(data_dicts)}")
    print(f"  - è®­ç»ƒé›† (80%): {len(train_files)} ä¾‹")
    print(f"  - éªŒè¯é›† (20%): {len(val_files)} ä¾‹")

    # ================= 2. åˆ›å»ºåŠ è½½å™¨ =================
    train_loader = get_basic_loader(
        data_list=train_files,
        batch_size=BATCH_SIZE, 
        roi_size=ROI_SIZE, 
        is_train=True, 
        num_workers=NUM_WORKERS,
        cache_rate=CACHE_RATE
    )
    
    val_loader = get_basic_loader(
        data_list=val_files,
        batch_size=1,
        roi_size=ROI_SIZE, 
        is_train=False, 
        num_workers=NUM_WORKERS,
        cache_rate=CACHE_RATE
    )

    # ================= 3. æ¨¡å‹ä¸ä¼˜åŒ–å™¨ =================
    model = UNet3D(in_channels=1, out_channels=2).to(device)
    loss_function = DiceCELoss(to_onehot_y=True, softmax=True)
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)
    dice_metric = DiceMetric(include_background=False, reduction="mean")
    scaler = torch.cuda.amp.GradScaler() if AMP else None

    # ================= 4. è®­ç»ƒå¾ªç¯ =================
    best_metric = -1
    best_metric_epoch = -1
    
    print(f"\n{'='*20} å¼€å§‹è®­ç»ƒ {'='*20}")
    
    for epoch in range(MAX_EPOCHS):
        epoch_start = time.time()
        model.train()
        epoch_loss = 0
        step = 0
        
        # --- Training (æ—  tqdm) ---
        for batch_data in train_loader:
            step += 1
            inputs, labels = batch_data["image"].to(device), batch_data["label"].to(device)

            optimizer.zero_grad()
            
            if AMP:
                with torch.cuda.amp.autocast():
                    outputs = model(inputs)
                    loss = loss_function(outputs, labels)
                scaler.scale(loss).backward()
                scaler.step(optimizer)
                scaler.update()
            else:
                outputs = model(inputs)
                loss = loss_function(outputs, labels)
                loss.backward()
                optimizer.step()

            epoch_loss += loss.item()
        
        epoch_loss /= step
        epoch_time = time.time() - epoch_start
        
        # æ‰“å°è®­ç»ƒæ—¥å¿—
        print(f"Epoch {epoch + 1}/{MAX_EPOCHS} | Time: {epoch_time:.1f}s | Train Loss: {epoch_loss:.4f}", end="")

        # --- Validation (æ—  tqdm) ---
        if (epoch + 1) % VAL_INTERVAL == 0:
            model.eval()
            with torch.no_grad():
                for val_data in val_loader:
                    val_inputs, val_labels = val_data["image"].to(device), val_data["label"].to(device)
                    
                    val_outputs = sliding_window_inference(
                        inputs=val_inputs, 
                        roi_size=ROI_SIZE, 
                        sw_batch_size=4, 
                        predictor=model
                    )
                    
                    val_outputs = [AsDiscrete(argmax=True, to_onehot=2)(i) for i in decollate_batch(val_outputs)]
                    val_labels = [AsDiscrete(to_onehot=2)(i) for i in decollate_batch(val_labels)]
                    
                    dice_metric(y_pred=val_outputs, y=val_labels)

                metric = dice_metric.aggregate().item()
                dice_metric.reset()

                print(f" | Val Dice: {metric:.4f}", end="")

                if metric > best_metric:
                    best_metric = metric
                    best_metric_epoch = epoch + 1
                    save_path = os.path.join(MODEL_SAVE_DIR, "best_metric_model.pth")
                    torch.save(model.state_dict(), save_path)
                    print(f" -> ğŸ”¥ New Best! ({best_metric:.4f})", end="")
        
        # æ¢è¡Œï¼Œä¸ºä¸‹ä¸€ä¸ª Epoch åšå‡†å¤‡
        print("") 

    print(f"\nè®­ç»ƒç»“æŸã€‚æœ€ä½³æ¨¡å‹ Dice: {best_metric:.4f} äº Epoch {best_metric_epoch}")

if __name__ == "__main__":
    try:
        train_baseline()
    except Exception as e:
        print(f"âŒ è®­ç»ƒå‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()