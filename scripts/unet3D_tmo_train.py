import sys
import os
import glob
import torch
import time
import warnings
import argparse

warnings.filterwarnings("ignore", category=UserWarning, module="monai.inferers.utils")

# --- è·¯å¾„é…ç½® ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from monai.losses import DiceCELoss
from monai.metrics import DiceMetric
from monai.inferers import sliding_window_inference
from monai.utils import set_determinism
from monai.data import decollate_batch, partition_dataset
from monai.transforms import AsDiscrete

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from src.models.unet3D import UNet3D
from src.dataloaders.basic_loader import get_basic_loader
from src.ssl.utils import update_ema_variables, get_current_consistency_weight, ConsistencyLoss
from src.ssl.tmo import TMOAdamW
from src.utils.config import load_config, get_config_argument_parser

def train_tmo(config):
    # ================= é…ç½®åŒºåŸŸ (Fail Fast) =================
    seed = config.get("seed", 2025)
    gpu_id = str(config["gpu_id"])
    os.environ["CUDA_VISIBLE_DEVICES"] = gpu_id
    print(f"ä½¿ç”¨GPU: {gpu_id}")

    data_dir = config["data_dir"]
    model_save_dir = config["model_save_dir"].format(seed=seed)
    os.makedirs(model_save_dir, exist_ok=True)

    load_batch_size_l = config["load_batch_size_l"]
    num_samples_l = config["num_samples_l"]

    load_batch_size_u = config["load_batch_size_u"]
    num_samples_u = config["num_samples_u"]

    num_labeled_use = config["num_labeled_use"]
    num_unlabeled_use = config["num_unlabeled_use"]

    max_iterations = config["max_iterations"]
    val_interval = config["val_interval"]

    lr = config["lr"]
    roi_size = tuple(config["roi_size"])

    ema_decay = config["ema_decay"]
    consistency = config["consistency"]
    # åŠ¨æ€è®¡ç®—æˆ–ä»é…ç½®è¯»å–
    consistency_rampup = config.get("consistency_rampup", max_iterations // 5)

    num_workers = config["num_workers"]
    cache_rate = config["cache_rate"]

    # ================= 1. æ•°æ®å‡†å¤‡ =================
    set_determinism(seed=seed)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ å¼€å§‹ TMO (Trusted Momentum) è®­ç»ƒ | è®¾å¤‡: {device}")
    print(f"ğŸ“Œ æ€»è®¡ {max_iterations} Iterations")
    print(f"å½“å‰éšæœºç§å­: {seed}")

    # A. å‡†å¤‡æœ‰æ ‡ç­¾æ•°æ® (Labeled)
    labeled_images = sorted(glob.glob(os.path.join(data_dir, "imagesTr", "*.nii.gz")))
    labeled_labels = sorted(glob.glob(os.path.join(data_dir, "labelsTr", "*.nii.gz")))
    labeled_dicts = [{"image": i, "label": l} for i, l in zip(labeled_images, labeled_labels)]

    # åˆ’åˆ† Train/Val
    train_labeled_files, val_files = partition_dataset(
        data=labeled_dicts, ratios=[0.8, 0.2], shuffle=True, seed=seed
    )

    # B. å‡†å¤‡æ— æ ‡ç­¾æ•°æ® (Unlabeled)
    unlabeled_dir = os.path.join(data_dir, "imagesUnlabeled")
    if os.path.exists(unlabeled_dir):
        unlabeled_images = sorted(glob.glob(os.path.join(unlabeled_dir, "*.nii.gz")))
        unlabeled_dicts = [{"image": i, "label": i} for i in unlabeled_images]

        import random
        # ç¡®ä¿éšæœºæ€§å—æ§
        random.seed(seed)
        random.shuffle(unlabeled_dicts)
        unlabeled_dicts = unlabeled_dicts[:num_unlabeled_use]
        print(f"âš ï¸ å·²é™åˆ¶æ— æ ‡ç­¾æ•°æ®é‡: {len(unlabeled_images)} -> {len(unlabeled_dicts)}")

        print(f"  - æœ‰æ ‡ç­¾æ•°æ® (Train): {len(train_labeled_files)} ä¾‹")
        print(f"  - æ— æ ‡ç­¾æ•°æ® (Train): {len(unlabeled_dicts)} ä¾‹")
    else:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° imagesUnlabeled æ–‡ä»¶å¤¹ï¼Œæ— æ³•è¿›è¡ŒåŠç›‘ç£è®­ç»ƒï¼")
        print(f"   è¯·ç¡®ä¿ç›®å½•å­˜åœ¨: {unlabeled_dir}")
        sys.exit(1)

    # C. åˆ›å»ºåŠ è½½å™¨
    # 1. æœ‰æ ‡ç­¾åŠ è½½å™¨
    loader_labeled = get_basic_loader(
        data_list=train_labeled_files,
        batch_size=load_batch_size_l,
        roi_size=roi_size,
        num_samples=num_samples_l,
        is_train=True,
        num_workers=num_workers,
        cache_rate=cache_rate,
    )

    # 2. æ— æ ‡ç­¾åŠ è½½å™¨
    loader_unlabeled = get_basic_loader(
        data_list=unlabeled_dicts,
        batch_size=load_batch_size_u,
        roi_size=roi_size,
        num_samples=num_samples_u,
        is_train=True,
        num_workers=num_workers,
        cache_rate=cache_rate,
    )

    # 3. éªŒè¯åŠ è½½å™¨
    loader_val = get_basic_loader(
        data_list=val_files,
        batch_size=1,
        roi_size=roi_size,
        is_train=False,
        num_workers=num_workers,
        cache_rate=cache_rate,
    )

    # ================= 2. æ¨¡å‹åˆå§‹åŒ– =================
    def create_model():
        model = UNet3D(in_channels=1, out_channels=2).to(device)
        return model

    model = create_model()          # Student
    ema_model = create_model()      # Teacher

    for param in ema_model.parameters():
        param.detach_()
    ema_model.load_state_dict(model.state_dict())

    # æŸå¤±å‡½æ•°
    loss_supervised = DiceCELoss(to_onehot_y=True, softmax=True)
    loss_consistency = ConsistencyLoss()

    # [æ ¸å¿ƒå·®å¼‚] ä½¿ç”¨ TMO ä¼˜åŒ–å™¨
    optimizer = TMOAdamW(model.parameters(), lr=lr)

    dice_metric = DiceMetric(include_background=False, reduction="mean")

    # ================= 3. è®­ç»ƒå¾ªç¯ (Iteration Based) =================
    best_metric = -1
    best_metric_iter = -1
    iteration = 0

    print(f"\n{'='*20} Start TMO Training (Iteration Based) {'='*20}")

    model.train()
    ema_model.train()

    iter_labeled = iter(loader_labeled)
    iter_unlabeled = iter(loader_unlabeled)

    start_time = time.time()
    loop_start_time = time.time()

    while iteration < max_iterations:
        # æ•°æ®è·å– (æ— é™å¾ªç¯)
        try:
            batch_l = next(iter_labeled)
        except StopIteration:
            iter_labeled = iter(loader_labeled)
            batch_l = next(iter_labeled)

        try:
            batch_u = next(iter_unlabeled)
        except StopIteration:
            iter_unlabeled = iter(loader_unlabeled)
            batch_u = next(iter_unlabeled)

        iteration += 1

        img_l, lbl_l = batch_l["image"].to(device), batch_l["label"].to(device)
        img_u = batch_u["image"].to(device)

        consistency_weight = get_current_consistency_weight(iteration, max_iterations, consistency, consistency_rampup)

        # -------------------------------------------------------
        # [TMO æ­¥éª¤ 1] Labeled Step: å»ºç«‹å¯ä¿¡æ–¹å‘ (Trusted Direction)
        # -------------------------------------------------------
        optimizer.zero_grad()

        pred_l = model(img_l)
        l_sup = loss_supervised(pred_l, lbl_l)

        # åå‘ä¼ æ’­äº§ç”Ÿ g_L
        l_sup.backward()
        optimizer.step_labeled()  # [TMO ç‰¹æœ‰] ä¿å­˜å¯ä¿¡æ¢¯åº¦æ–¹å‘

        # -------------------------------------------------------
        # [TMO æ­¥éª¤ 2] Unlabeled Step: è°¨æ…æ›´æ–° (Cautious Update)
        # -------------------------------------------------------
        optimizer.zero_grad()

        # Student Forward
        pred_u_student = model(img_u)
        # Teacher Forward (No Grad)
        with torch.no_grad():
            pred_u_teacher = ema_model(img_u)

        # è®¡ç®—ä¸€è‡´æ€§æŸå¤±
        student_prob = torch.softmax(pred_u_student, dim=1)
        teacher_prob = torch.softmax(pred_u_teacher, dim=1)
        l_cons = loss_consistency(student_prob, teacher_prob)
        total_loss_cons = consistency_weight * l_cons

        # åå‘ä¼ æ’­äº§ç”Ÿ g_U
        total_loss_cons.backward()
        optimizer.step_unlabeled()  # [TMO ç‰¹æœ‰] æ ¹æ® g_L è¿‡æ»¤ g_U

        # -------------------------------------------------------
        # [æ­¥éª¤ 3] Teacher EMA æ›´æ–°
        # -------------------------------------------------------
        update_ema_variables(model, ema_model, ema_decay, iteration)

        # --- Logging ---
        current_time = time.time()
        iter_time = current_time - loop_start_time
        loop_start_time = current_time

        if iteration % 10 == 0:
            print(f"Iter {iteration}/{max_iterations} | Time: {iter_time:.4f}s | "
                  f"L_Sup: {l_sup.item():.4f} | L_Cons: {l_cons.item():.4f} (w={consistency_weight:.3f})")

        # --- Validation (ä½¿ç”¨ Teacher è¯„ä¼°) ---
        if iteration % val_interval == 0:
            torch.cuda.empty_cache()

            ema_model.eval()
            with torch.no_grad():
                for val_data in loader_val:
                    val_in, val_lbl = val_data["image"].to(device), val_data["label"].to(device)
                    val_out = sliding_window_inference(val_in, roi_size, 4, ema_model)
                    val_out = [AsDiscrete(argmax=True, to_onehot=2)(i) for i in decollate_batch(val_out)]
                    val_lbl = [AsDiscrete(to_onehot=2)(i) for i in decollate_batch(val_lbl)]
                    dice_metric(y_pred=val_out, y=val_lbl)

                metric = dice_metric.aggregate().item()
                dice_metric.reset()

                print(f"Validation at Iter {iteration} | Val Dice: {metric:.4f}", end="")

                if metric > best_metric:
                    best_metric = metric
                    best_metric_iter = iteration
                    # torch.save(ema_model.state_dict(), os.path.join(MODEL_SAVE_DIR, "best_teacher_tmo.pth"))
                    # torch.save(model.state_dict(), os.path.join(MODEL_SAVE_DIR, "best_student_tmo.pth"))
                    print(f" -> ğŸ”¥ New Best! ({best_metric:.4f})")
                else:
                    print("")

            torch.cuda.empty_cache()

            model.train()
            ema_model.train()

    total_time = time.time() - start_time
    print(f"\nè®­ç»ƒç»“æŸã€‚æ€»ç”¨æ—¶: {total_time:.1f}s")
    print(f"æœ€ä½³æ¨¡å‹ Dice: {best_metric:.4f} äº Iteration {best_metric_iter}")

if __name__ == "__main__":
    parser = get_config_argument_parser(description="UNet3D TMO åŠç›‘ç£è®­ç»ƒè„šæœ¬")
    parser.add_argument("--seed", type=int, default=2025, help="éšæœºç§å­ (é»˜è®¤: 2025)")
    args = parser.parse_args()

    # åŠ è½½é…ç½®
    default_config_path = os.path.join(project_root, "configs", "unet3D_tmo_train.yaml")
    config_path = args.config if args.config else default_config_path

    config = load_config(config_path, default_config=None)

    if not config:
        print(f"âŒ é”™è¯¯: æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶ {config_path}ï¼Œæˆ–æ–‡ä»¶ä¸ºç©ºï¼")
        sys.exit(1)

    if args.seed != 2025:
        config["seed"] = args.seed
    elif "seed" not in config:
        config["seed"] = 2025

    try:
        train_tmo(config)
    except Exception as e:
        print(f"âŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
