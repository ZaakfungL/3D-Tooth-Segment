import sys
import os
import glob
import torch
import numpy as np
import itertools # [æ–°å¢] ç”¨äºå¾ªç¯æ•°æ®é›†
from tqdm import tqdm
import time
import warnings

# [æ–°å¢] å¿½ç•¥æ¥è‡ª MONAI/PyTorch çš„ç‰¹å®šæœªæ¥è­¦å‘Šï¼Œä¿æŒæ—¥å¿—å¹²å‡€
warnings.filterwarnings("ignore", category=UserWarning, module="monai.inferers.utils")

# --- è·¯å¾„é…ç½® ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from monai.losses import DiceCELoss
from monai.metrics import DiceMetric
from monai.inferers import sliding_window_inference
from monai.utils import set_determinism
from monai.data import decollate_batch, partition_dataset
from monai.transforms import AsDiscrete

# å¯¼å…¥ä½ çš„æ¨¡å—
from src.models.unet3D import UNet3D
from src.dataloaders.basic_loader import get_basic_loader
from src.ssl.utils import update_ema_variables, get_current_consistency_weight, ConsistencyLoss

def train_ssl():
    # ================= é…ç½®åŒºåŸŸ =================
    DATA_DIR = "/home/lzf/Code/dataset/nnUNet_raw/Dataset701_STS3D_ROI"
    MODEL_SAVE_DIR = "./weights/ssl_meanteacher"
    os.makedirs(MODEL_SAVE_DIR, exist_ok=True)
    
    # SSL è¶…å‚æ•°
    MAX_EPOCHS = 5
    VAL_INTERVAL = 2
    LR = 1e-4
    ROI_SIZE = (64, 64, 64)
    
    # [æ ¸å¿ƒä¿®æ”¹] æ¯”ä¾‹æ§åˆ¶åŒºåŸŸ
    # è¿™é‡Œæ§åˆ¶ä¸€ä¸ª Batch å†… "æœ‰æ ‡ç­¾:æ— æ ‡ç­¾" çš„æ•°é‡æ¯”ä¾‹
    # æ˜¾å­˜å ç”¨ â‰ˆ (BATCH_SIZE_L + BATCH_SIZE_U) * æ˜¾å­˜æ¶ˆè€—
    # å»ºè®®: ä¿æŒ 1:1 (2 vs 2) æˆ– 1:2 (1 vs 2) é˜²æ­¢æ˜¾å­˜çˆ†ç‚¸
    BATCH_SIZE_L = 1  # æœ‰æ ‡ç­¾ Batch Size
    BATCH_SIZE_U = 1  # æ— æ ‡ç­¾ Batch Size (å¢å¤§æ­¤å€¼å¯å®ç° 1:N)
    
    # Mean Teacher å‚æ•°
    EMA_DECAY = 0.99       
    CONSISTENCY = 0.1      
    CONSISTENCY_RAMPUP = 20 
    
    # èµ„æºé…ç½®
    AMP = True
    NUM_WORKERS = 2
    CACHE_RATE = 0.0

    # ================= 1. æ•°æ®å‡†å¤‡ =================
    set_determinism(seed=2025)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ å¼€å§‹ Mean Teacher è®­ç»ƒ | è®¾å¤‡: {device}")
    print(f"ğŸ“Œ Batch æ¯”ä¾‹é…ç½®: Labeled={BATCH_SIZE_L} : Unlabeled={BATCH_SIZE_U}")

    # A. å‡†å¤‡æœ‰æ ‡ç­¾æ•°æ® (Labeled)
    labeled_images = sorted(glob.glob(os.path.join(DATA_DIR, "imagesTr", "*.nii.gz")))
    labeled_labels = sorted(glob.glob(os.path.join(DATA_DIR, "labelsTr", "*.nii.gz")))
    labeled_dicts = [{"image": i, "label": l} for i, l in zip(labeled_images, labeled_labels)]
    
    # åˆ’åˆ† Train/Val
    train_labeled_files, val_files = partition_dataset(
        data=labeled_dicts, ratios=[0.8, 0.2], shuffle=True, seed=2025
    )

    # B. å‡†å¤‡æ— æ ‡ç­¾æ•°æ® (Unlabeled)
    unlabeled_dir = os.path.join(DATA_DIR, "imagesUnlabeled")
    if os.path.exists(unlabeled_dir):
        unlabeled_images = sorted(glob.glob(os.path.join(unlabeled_dir, "*.nii.gz")))
        unlabeled_dicts = [{"image": i, "label": i} for i in unlabeled_images]
        print(f"  - æœ‰æ ‡ç­¾æ•°æ® (Train): {len(train_labeled_files)} ä¾‹")
        print(f"  - æ— æ ‡ç­¾æ•°æ® (Train): {len(unlabeled_dicts)} ä¾‹")
    else:
        print("âŒ è­¦å‘Š: æœªæ‰¾åˆ° imagesUnlabeled æ–‡ä»¶å¤¹ï¼Œå›é€€åˆ°çº¯ç›‘ç£æ¨¡å¼ï¼")
        unlabeled_dicts = train_labeled_files 

    # C. åˆ›å»ºåŠ è½½å™¨
    # 1. æœ‰æ ‡ç­¾åŠ è½½å™¨ (ä½¿ç”¨ BATCH_SIZE_L)
    loader_labeled = get_basic_loader(
        data_list=train_labeled_files,
        batch_size=BATCH_SIZE_L, 
        roi_size=ROI_SIZE, 
        is_train=True, 
        num_workers=NUM_WORKERS,
        cache_rate=CACHE_RATE,
        limit=1
    )
    
    # 2. æ— æ ‡ç­¾åŠ è½½å™¨ (ä½¿ç”¨ BATCH_SIZE_U)
    loader_unlabeled = get_basic_loader(
        data_list=unlabeled_dicts,
        batch_size=BATCH_SIZE_U, 
        roi_size=ROI_SIZE, 
        is_train=True, 
        num_workers=NUM_WORKERS,
        cache_rate=CACHE_RATE,
        limit=1
    )
    
    # 3. éªŒè¯åŠ è½½å™¨
    loader_val = get_basic_loader(
        data_list=val_files,
        batch_size=1, 
        roi_size=ROI_SIZE, 
        is_train=False, 
        num_workers=NUM_WORKERS,
        cache_rate=CACHE_RATE,
        limit=1
    )

    # ================= 2. æ¨¡å‹åˆå§‹åŒ– =================
    def create_model():
        model = UNet3D(in_channels=1, out_channels=2).to(device)
        return model

    model = create_model()          # Student
    ema_model = create_model()      # Teacher

    for param in ema_model.parameters():
        param.detach_() 
    ema_model.load_state_dict(model.state_dict())

    loss_supervised = DiceCELoss(to_onehot_y=True, softmax=True)
    loss_consistency = ConsistencyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)
    scaler = torch.amp.GradScaler('cuda') if AMP else None
    dice_metric = DiceMetric(include_background=False, reduction="mean")

    # ================= 3. è®­ç»ƒå¾ªç¯ =================
    best_metric = -1
    
    print(f"\n{'='*20} Start Training {'='*20}")

    for epoch in range(MAX_EPOCHS):
        epoch_start = time.time()
        model.train()
        ema_model.train()
        
        loss_sup_sum = 0
        loss_cons_sum = 0
        step = 0
        
        consistency_weight = get_current_consistency_weight(epoch, MAX_EPOCHS, CONSISTENCY, CONSISTENCY_RAMPUP)
        
        # [æ ¸å¿ƒä¿®æ”¹] å¾ªç¯ç­–ç•¥
        # ä½¿ç”¨ zip(loader_unlabeled, itertools.cycle(loader_labeled))
        # 1. ä»¥ loader_unlabeled (å¤§æ•°æ®é›†) çš„é•¿åº¦ä¸ºå‡†ï¼Œä¿è¯æ¯ä¸ª Epoch éå†å®Œæ‰€æœ‰æ— æ ‡ç­¾æ•°æ®
        # 2. loader_labeled (å°æ•°æ®é›†) ä¼šæ— é™å¾ªç¯ï¼Œç›´åˆ°æ— æ ‡ç­¾æ•°æ®è·‘å®Œ
        # 3. è¿™æ ·å®ç°äº† "1ä¸ªEpochå†…ï¼Œæ‰€æœ‰æ— æ ‡ç­¾æ•°æ®è¢«è®­ç»ƒ1æ¬¡ï¼Œæœ‰æ ‡ç­¾æ•°æ®è¢«é‡å¤è®­ç»ƒå¤šæ¬¡"
        
        train_iterator = zip(loader_unlabeled, itertools.cycle(loader_labeled))
        
        for batch_u, batch_l in train_iterator:
            step += 1
            
            img_l, lbl_l = batch_l["image"].to(device), batch_l["label"].to(device)
            img_u = batch_u["image"].to(device)
            
            optimizer.zero_grad()
            
            with torch.amp.autocast('cuda', enabled=AMP):
                # 1. Forward
                pred_l_student = model(img_l)
                pred_u_student = model(img_u)

                with torch.no_grad():
                    pred_u_teacher = ema_model(img_u)
                
                # 2. Loss
                # Labeled Loss
                l_sup = loss_supervised(pred_l_student, lbl_l)
                
                # Unlabeled Loss (Consistency)
                student_prob = torch.softmax(pred_u_student, dim=1)
                teacher_prob = torch.softmax(pred_u_teacher, dim=1)
                l_cons = loss_consistency(student_prob, teacher_prob)
                
                total_loss = l_sup + consistency_weight * l_cons

            # 3. Backward
            scaler.scale(total_loss).backward()
            scaler.step(optimizer)
            scaler.update()
            
            # 4. EMA Update
            # ä½¿ç”¨å…¨å±€æ­¥æ•° (epoch * steps_per_epoch + step) å¯èƒ½ä¼šå› ä¸º steps å˜åŒ–è€Œä¸å‡†
            # è¿™é‡Œç®€å•ç´¯åŠ å³å¯
            update_ema_variables(model, ema_model, EMA_DECAY, epoch * 100 + step)
            
            loss_sup_sum += l_sup.item()
            loss_cons_sum += l_cons.item()

        epoch_time = time.time() - epoch_start
        print(f"Ep {epoch+1}/{MAX_EPOCHS} | Time: {epoch_time:.0f}s | Steps: {step} | "
              f"L_Sup: {loss_sup_sum/max(step,1):.4f} | "
              f"L_Cons (w={consistency_weight:.3f}): {loss_cons_sum/max(step,1):.4f}", end="")

        # --- Validation ---
        if (epoch + 1) % VAL_INTERVAL == 0:
            ema_model.eval()
            with torch.no_grad():
                for val_data in loader_val:
                    val_in, val_lbl = val_data["image"].to(device), val_data["label"].to(device)
                    val_out = sliding_window_inference(val_in, ROI_SIZE, 4, ema_model)
                    val_out = [AsDiscrete(argmax=True, to_onehot=2)(i) for i in decollate_batch(val_out)]
                    val_lbl = [AsDiscrete(to_onehot=2)(i) for i in decollate_batch(val_lbl)]
                    dice_metric(y_pred=val_out, y=val_lbl)
                
                metric = dice_metric.aggregate().item()
                dice_metric.reset()
                
                print(f" | Val Dice: {metric:.4f}", end="")
                
                if metric > best_metric:
                    best_metric = metric
                    # torch.save(ema_model.state_dict(), os.path.join(MODEL_SAVE_DIR, "best_teacher.pth"))
                    print(f" -> ğŸ”¥ Saved!", end="")

        print("")

    print(f"è®­ç»ƒç»“æŸã€‚Best Dice: {best_metric:.4f}")

if __name__ == "__main__":
    train_ssl()