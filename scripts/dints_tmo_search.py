import os
import sys
import glob
import torch
import numpy as np
import time
import warnings
import json

# è¿‡æ»¤ä¸å¿…è¦çš„è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="monai.inferers.utils")

# --- è·¯å¾„é…ç½® ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from monai.config import print_config
from monai.utils import set_determinism
from monai.losses import DiceCELoss
from monai.metrics import DiceMetric
from monai.data import decollate_batch
from monai.inferers import sliding_window_inference
from monai.transforms import AsDiscrete

from src.dataloaders.combo_loader import NASComboDataLoader
from src.models.dints import DiNTSWrapper
from src.ssl.tmo import TMOAdamW
from src.ssl.utils import update_ema_variables, ConsistencyLoss, get_current_consistency_weight

# --- é…ç½® (ç›®å‰ä¸ºç¡¬ç¼–ç ï¼Œç”¨äºéªŒè¯) ---
DATA_DIR = "/home/lzf/Code/dataset/nnUNet_raw/Dataset701_STS3D_ROI"
LOG_DIR = "./results/dints_tmo_search"
MAX_EPOCHS = 200
BATCH_SIZE = 2
LR_WEIGHTS = 0.025
LR_ARCH = 0.003
VAL_FREQ = 5              # æ¯ 5 epoch éªŒè¯
ARCH_START_EPOCH = 10     # å‰ 10 epoch åªè®­ç»ƒæƒé‡
EMA_ALPHA = 0.99
CONSISTENCY = 10.0
CONSISTENCY_RAMPUP = 30.0
ROI_SIZE = (96,96,96)

# --- DataLoader é…ç½® ---
NUM_WORKERS = 4
CACHE_RATE = 1          # åˆ©ç”¨ 90GB RAM

def search_tmo():
    # 0. è®¾ç½®
    if not os.path.exists(LOG_DIR):
        os.makedirs(LOG_DIR)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    set_determinism(0)
    
    print(f"ğŸš€ å¼€å§‹ DiNTS-TMO æœç´¢ | è®¾å¤‡: {device}")

    # 1. æ¨¡å‹åˆå§‹åŒ–
    print("åˆå§‹åŒ–æ¨¡å‹...")
    # Student: éœ€è¦æ¢¯åº¦
    student = DiNTSWrapper(
        in_channels=1, 
        out_channels=2, 
        num_blocks=6, 
        num_depths=3
    ).to(device)
    
    # Teacher: ä¸éœ€è¦æ¢¯åº¦ï¼Œä½¿ç”¨ EMA æƒé‡
    teacher = DiNTSWrapper(
        in_channels=1, 
        out_channels=2, 
        num_blocks=6, 
        num_depths=3
    ).to(device)
    
    # å¦‚æœéœ€è¦ï¼Œæ˜¾å¼è®¾ç½® dints_space çš„è®¾å¤‡
    if hasattr(student, "dints_space"):
        student.dints_space.device = device
    if hasattr(teacher, "dints_space"):
        teacher.dints_space.device = device
    
    # åˆ†ç¦» Teacher å‚æ•°
    for p in teacher.parameters():
        p.detach_()

    # 2. æ•°æ®åŠ è½½å™¨
    print("åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨...")
    
    # ===== å…ˆåˆ’åˆ† Train/Valï¼Œé¿å…æ•°æ®æ³„æ¼ =====
    from monai.data import partition_dataset
    from src.dataloaders.basic_loader import get_basic_loader
    
    # æ‰«ææœ‰æ ‡ç­¾æ•°æ®
    images_l = sorted(glob.glob(os.path.join(DATA_DIR, "imagesTr", "*.nii.gz")))
    labels_l = sorted(glob.glob(os.path.join(DATA_DIR, "labelsTr", "*.nii.gz")))
    all_labeled = [{"image": i, "label": l} for i, l in zip(images_l, labels_l)]
    
    # åˆ’åˆ† Train/Val (80%/20%)ï¼Œä¿è¯äº’æ–¥
    train_labeled, val_labeled = partition_dataset(
        data=all_labeled, ratios=[0.8, 0.2], shuffle=True, seed=2025
    )
    print(f"ğŸ“Š Train/Val åˆ’åˆ†: Train {len(train_labeled)} ä¾‹ | Val {len(val_labeled)} ä¾‹")
    
    # æ‰«ææ— æ ‡ç­¾æ•°æ® (ä¸éœ€è¦åˆ’åˆ†ï¼Œå…¨éƒ¨ç”¨äºè®­ç»ƒ)
    images_u = sorted(glob.glob(os.path.join(DATA_DIR, "imagesUnlabeled", "*.nii.gz")))
    all_unlabeled = [{"image": i, "label": i} for i in images_u]  # label å ä½ï¼Œä¸ä½¿ç”¨
    
    # ===== æ§åˆ¶æœ‰æ ‡ç­¾/æ— æ ‡ç­¾æ¯”ä¾‹ =====
    # æŒ‰ 1:1 æ¯”ä¾‹æˆªå–æ— æ ‡ç­¾æ•°æ®ï¼Œé¿å…åŠ è½½è¿‡å¤šæ•°æ®æµªè´¹ RAM
    unlabeled_ratio = 1.0  # æ— æ ‡ç­¾æ•°æ®æ˜¯æœ‰æ ‡ç­¾çš„å¤šå°‘å€ (1.0 = 1:1)
    max_unlabeled = int(len(train_labeled) * unlabeled_ratio)
    if len(all_unlabeled) > max_unlabeled:
        # éšæœºé‡‡æ ·ï¼Œä¿è¯å¤šæ ·æ€§
        import random
        random.seed(2025)
        all_unlabeled = random.sample(all_unlabeled, max_unlabeled)
    print(f"ğŸ“Š æ— æ ‡ç­¾æ•°æ®: {len(all_unlabeled)} ä¾‹ (æ¯”ä¾‹ 1:{unlabeled_ratio})")
    
    # ===== åˆ›å»º NASComboDataLoader (åªç”¨è®­ç»ƒæ•°æ®) =====
    combo_loader = NASComboDataLoader(
        labeled_list=train_labeled,      # ä¼ å…¥åˆ’åˆ†å¥½çš„æœ‰æ ‡ç­¾è®­ç»ƒé›†
        unlabeled_list=all_unlabeled,    # ä¼ å…¥å…¨éƒ¨æ— æ ‡ç­¾æ•°æ®
        batch_size_l=BATCH_SIZE,
        batch_size_u=BATCH_SIZE,
        roi_size=ROI_SIZE,
        num_workers=NUM_WORKERS,
        cache_rate=CACHE_RATE,
        # limit=4  # è°ƒè¯•æ—¶å–æ¶ˆæ³¨é‡Š
    )
    
    # ===== åˆ›å»ºéªŒè¯åŠ è½½å™¨ =====
    val_loader = get_basic_loader(
        data_list=val_labeled,
        batch_size=1,
        roi_size=ROI_SIZE,
        is_train=False,
        num_workers=NUM_WORKERS,
        cache_rate=CACHE_RATE
    )

    # 3. ä¼˜åŒ–å™¨åˆå§‹åŒ–
    print("åˆå§‹åŒ–ä¼˜åŒ–å™¨ (TMO)...")
    optimizer_w = TMOAdamW(student.weight_parameters(), lr=LR_WEIGHTS, weight_decay=1e-4)
    optimizer_a = TMOAdamW(student.arch_parameters(), lr=LR_ARCH, weight_decay=1e-3)

    # 4. æŸå¤±å‡½æ•°
    loss_dice_ce = DiceCELoss(to_onehot_y=True, softmax=True, batch=True)
    loss_consistency = ConsistencyLoss()
    dice_metric = DiceMetric(include_background=False, reduction="mean")

    # --- è®­ç»ƒå¾ªç¯ ---
    print(f"\n{'='*20} å¼€å§‹æœç´¢å¾ªç¯ ({MAX_EPOCHS} epochs) {'='*20}")
    global_step = 0
    best_metric = -1
    
    for epoch in range(MAX_EPOCHS):
        epoch_start = time.time()
        student.train()
        teacher.train() 
        
        loss_w_l_sum = 0
        loss_w_u_sum = 0
        loss_a_l_sum = 0
        loss_a_u_sum = 0
        step = 0
        
        cons_weight = get_current_consistency_weight(epoch, MAX_EPOCHS, CONSISTENCY, CONSISTENCY_RAMPUP)
        
        for batch_data in combo_loader:
            step += 1
            global_step += 1
            
            l_w_imgs, l_w_lbls = batch_data['l_w']['image'].to(device), batch_data['l_w']['label'].to(device)
            u_w_imgs = batch_data['u_w']['image'].to(device)
            l_a_imgs, l_a_lbls = batch_data['l_a']['image'].to(device), batch_data['l_a']['label'].to(device)
            u_a_imgs = batch_data['u_a']['image'].to(device)

            # --- é˜¶æ®µ A: ä¼˜åŒ–æ¶æ„å‚æ•° (Alpha) ---
            if epoch >= ARCH_START_EPOCH:
                # A1. æœ‰æ ‡ç­¾æ­¥éª¤ (Labeled Step)
                optimizer_a.zero_grad()
                outputs_l_a = student(l_a_imgs)
                loss_a_l = loss_dice_ce(outputs_l_a, l_a_lbls)
                
                # ç†µæŸå¤± (å¯é€‰ï¼Œæ¨¡ä»¿ dints_search çš„è¡Œä¸º)
                probs_children, _ = student.dints_space.get_prob_a(child=True)
                entropy_loss = student.dints_space.get_topology_entropy(probs_children)
                loss_a_l_total = loss_a_l + 0.001 * entropy_loss
                
                loss_a_l_total.backward()
                optimizer_a.step_labeled()
                loss_a_l_sum += loss_a_l.item()

                # A2. æ— æ ‡ç­¾æ­¥éª¤ (Unlabeled Step)
                optimizer_a.zero_grad()
                
                # åŒæ­¥ Teacher æ¶æ„
                with torch.no_grad():
                    teacher.dints_space.log_alpha_a.copy_(student.dints_space.log_alpha_a)
                    teacher.dints_space.log_alpha_c.copy_(student.dints_space.log_alpha_c)
                
                outputs_u_a = student(u_a_imgs)
                with torch.no_grad():
                    teacher_u_a = teacher(u_a_imgs)
                    teacher_u_a = torch.softmax(teacher_u_a, dim=1)
                
                student_u_a_soft = torch.softmax(outputs_u_a, dim=1)
                loss_a_u = loss_consistency(student_u_a_soft, teacher_u_a) * cons_weight
                
                loss_a_u.backward()
                optimizer_a.step_unlabeled()
                loss_a_u_sum += loss_a_u.item()
            
            # --- é˜¶æ®µ B: ä¼˜åŒ–æƒé‡å‚æ•° (Weights) ---
            # B1. æœ‰æ ‡ç­¾æ­¥éª¤ (Labeled Step)
            optimizer_w.zero_grad()
            outputs_l_w = student(l_w_imgs)
            loss_w_l = loss_dice_ce(outputs_l_w, l_w_lbls)
            
            loss_w_l.backward()
            optimizer_w.step_labeled()
            loss_w_l_sum += loss_w_l.item()
            
            # B2. æ— æ ‡ç­¾æ­¥éª¤ (Unlabeled Step)
            optimizer_w.zero_grad()
            outputs_u_w = student(u_w_imgs)
            with torch.no_grad():
                teacher_u_w = teacher(u_w_imgs)
                teacher_u_w = torch.softmax(teacher_u_w, dim=1)
            
            student_u_w_soft = torch.softmax(outputs_u_w, dim=1)
            loss_w_u = loss_consistency(student_u_w_soft, teacher_u_w) * cons_weight
            
            loss_w_u.backward()
            optimizer_w.step_unlabeled()
            loss_w_u_sum += loss_w_u.item()

            # --- é˜¶æ®µ C: ç»´æŠ¤ ---
            update_ema_variables(student, teacher, EMA_ALPHA, global_step)

        # Epoch ç»“æŸæ—¥å¿—
        epoch_time = time.time() - epoch_start
        print(f"Ep {epoch+1}/{MAX_EPOCHS} | Time: {epoch_time:.1f}s | "
              f"L_W(L): {loss_w_l_sum/max(step,1):.4f} L_W(U): {loss_w_u_sum/max(step,1):.4f} | "
              f"L_A(L): {loss_a_l_sum/max(step,1):.4f} L_A(U): {loss_a_u_sum/max(step,1):.4f}", end="")

        # éªŒè¯
        if (epoch + 1) % VAL_FREQ == 0:
            teacher.eval() # ä½¿ç”¨ Teacher è¿›è¡ŒéªŒè¯
            with torch.no_grad():
                for val_data in val_loader:
                    val_in, val_lbl = val_data["image"].to(device), val_data["label"].to(device)
                    val_pred = sliding_window_inference(val_in, ROI_SIZE, 4, teacher)
                    val_pred = [AsDiscrete(argmax=True, to_onehot=2)(i) for i in decollate_batch(val_pred)]
                    val_lbl = [AsDiscrete(to_onehot=2)(i) for i in decollate_batch(val_lbl)]
                    dice_metric(y_pred=val_pred, y=val_lbl)
                
                metric = dice_metric.aggregate().item()
                dice_metric.reset()
                
                print(f" | Val Dice: {metric:.4f}", end="")
                
                if metric > best_metric:
                    best_metric = metric
                    # ä¿å­˜æœ€ä½³ç»“æœ
                    topology = teacher.get_topology()
                    arch_json = {"arch_code_a": topology[1].tolist(), "arch_code_c": topology[2].tolist()}
                    with open(os.path.join(LOG_DIR, "best_arch.json"), "w") as f:
                        json.dump(arch_json, f)
                    torch.save(teacher.state_dict(), os.path.join(LOG_DIR, "model_best.pth"))
                    print(f" -> ğŸ”¥ New Best!", end="")
        
        print("")

    print(f"\næœç´¢ç»“æŸã€‚æœ€ä½³ Dice: {best_metric:.4f}")

if __name__ == "__main__":
    try:
        search_tmo()
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # é˜²æ­¢åœ¨ç®—åŠ›å¹³å°ä¸Šæµªè´¹é’±ï¼šç­‰å¾…60ç§’åè‡ªåŠ¨å…³æœº
        print("\nâ° 60ç§’åè‡ªåŠ¨å…³æœºï¼ŒæŒ‰ Ctrl+C å–æ¶ˆ...")
        import time
        import subprocess
        try:
            time.sleep(60)
            print("ğŸ”Œ æ­£åœ¨å…³æœº...")
            subprocess.run(["shutdown", "-h", "now"], check=False)
        except KeyboardInterrupt:
            print("âŒ å…³æœºå·²å–æ¶ˆ")
