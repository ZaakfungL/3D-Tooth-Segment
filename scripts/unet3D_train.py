import sys
import os
import glob
import torch
import time
import warnings
import argparse

# [æ–°å¢] å¿½ç•¥æ¥è‡ª MONAI/PyTorch çš„ç‰¹å®šæœªæ¥è­¦å‘Šï¼Œä¿æŒæ—¥å¿—å¹²å‡€
warnings.filterwarnings("ignore", category=UserWarning, module="monai.inferers.utils")

# --- è·¯å¾„é…ç½® ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.append(project_root)

from monai.losses import DiceCELoss
from monai.metrics import DiceMetric
from monai.inferers import sliding_window_inference
from monai.utils import set_determinism
from monai.data import decollate_batch, partition_dataset
from monai.transforms import AsDiscrete

# å¯¼å…¥ä½ çš„æ¨¡å—
from src.models.unet3D import UNet3D
from src.dataloaders.basic_loader import get_basic_loader
from src.utils.config import load_config, get_config_argument_parser

def train_baseline(config):
    # ================= é…ç½®åŒºåŸŸ (Fail Fast) =================
    seed = config.get("seed", 2025)
    gpu_id = str(config["gpu_id"])
    os.environ["CUDA_VISIBLE_DEVICES"] = gpu_id
    print(f"ä½¿ç”¨GPU: {gpu_id}")

    data_dir = config["data_dir"]
    model_save_dir = config["model_save_dir"].format(seed=seed)
    os.makedirs(model_save_dir, exist_ok=True)

    # è®­ç»ƒè¶…å‚æ•°ï¼ˆåŸºäºiterationï¼‰
    max_iterations = config["max_iterations"]
    val_interval = config["val_interval"]

    load_batch_size = config["load_batch_size"]
    num_samples = config["num_samples"]

    lr = config["lr"]
    roi_size = tuple(config["roi_size"])

    num_workers = config["num_workers"]
    cache_rate = config["cache_rate"]

    # ================= 1. æ•°æ®å‡†å¤‡ =================
    set_determinism(seed=seed)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"å½“å‰éšæœºç§å­: {seed}")

    print("æ­£åœ¨æ‰«æå¹¶åˆ’åˆ†æ•°æ®é›†...")
    images = sorted(glob.glob(os.path.join(data_dir, "imagesTr", "*.nii.gz")))
    labels = sorted(glob.glob(os.path.join(data_dir, "labelsTr", "*.nii.gz")))

    if not images:
        raise ValueError(f"é”™è¯¯ï¼šåœ¨ {data_dir} ä¸­æœªæ‰¾åˆ°æ•°æ®ï¼")

    data_dicts = [{"image": img, "label": lbl} for img, lbl in zip(images, labels)]

    train_files, val_files = partition_dataset(
        data=data_dicts,
        ratios=[0.8, 0.2],
        shuffle=True,
        seed=seed
    )

    print(f"  - æ€»æ•°æ®é‡: {len(data_dicts)}")
    print(f"  - è®­ç»ƒé›† (80%): {len(train_files)} ä¾‹")
    print(f"  - éªŒè¯é›† (20%): {len(val_files)} ä¾‹")

    # ================= 2. åˆ›å»ºåŠ è½½å™¨ =================
    train_loader = get_basic_loader(
        data_list=train_files,
        batch_size=load_batch_size,
        roi_size=roi_size,
        num_samples=num_samples, # [æ–°å¢] å¯ç”¨å¤šæ ·æœ¬é‡‡æ ·
        is_train=True,
        num_workers=num_workers,
        cache_rate=cache_rate,
    )

    val_loader = get_basic_loader(
        data_list=val_files,
        batch_size=1,
        roi_size=roi_size,
        is_train=False,
        num_workers=num_workers,
        cache_rate=cache_rate,
    )

    # ================= 3. æ¨¡å‹ä¸ä¼˜åŒ–å™¨ =================
    model = UNet3D(in_channels=1, out_channels=2).to(device)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"æ¨¡å‹æ€»å‚æ•°é‡: {total_params:,}")

    loss_function = DiceCELoss(to_onehot_y=True, softmax=True)
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)
    dice_metric = DiceMetric(include_background=False, reduction="mean")

    # ================= 4. è®­ç»ƒå¾ªç¯ =================
    best_metric = -1
    best_metric_iteration = -1
    iteration = 0
    epoch_loss = 0
    step_in_epoch = 0

    print(f"\n{'='*20} å¼€å§‹è®­ç»ƒ (åŸºäºIteration) {'='*20}")
    print(f"æœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}, éªŒè¯é—´éš”: {val_interval} iterations")

    model.train()
    train_iter = iter(train_loader)
    start_time = time.time() # è®°å½•æ€»å¼€å§‹æ—¶é—´
    loop_start_time = time.time() # è®°å½•å¾ªç¯å¼€å§‹æ—¶é—´

    while iteration < max_iterations:
        # è·å–ä¸‹ä¸€ä¸ªbatchï¼Œå¦‚æœæ•°æ®ç”¨å®Œåˆ™é‡æ–°å¼€å§‹
        try:
            batch_data = next(train_iter)
        except StopIteration:
            train_iter = iter(train_loader)
            batch_data = next(train_iter)

        iteration += 1
        step_in_epoch += 1

        inputs, labels_batch = batch_data["image"].to(device), batch_data["label"].to(device)

        optimizer.zero_grad()

        outputs = model(inputs)
        loss = loss_function(outputs, labels_batch)
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()

        # æ‰“å°è®­ç»ƒè¿›åº¦
        current_loss = loss.item()

        if iteration % 10 == 0:
            current_time = time.time()
            iter_time = current_time - loop_start_time
            loop_start_time = current_time  # åªåœ¨æ‰“å°åé‡ç½®
            print(f"Iteration {iteration}/{max_iterations} | Time: {iter_time:.2f}s | Loss: {current_loss:.4f}")

        # --- Validation ---
        if iteration % val_interval == 0:
            # [ä¼˜åŒ–] éªŒè¯å‰æ¸…ç†æ˜¾å­˜ï¼Œä¸ºéªŒè¯é˜¶æ®µè…¾å‡ºç©ºé—´
            torch.cuda.empty_cache()
            val_start_time = time.time()

            model.eval()
            with torch.no_grad():
                for val_data in val_loader:
                    val_inputs, val_labels = val_data["image"].to(device), val_data["label"].to(device)

                    val_outputs = sliding_window_inference(
                        inputs=val_inputs,
                        roi_size=roi_size,
                        sw_batch_size=4,
                        predictor=model
                    )

                    val_outputs = [AsDiscrete(argmax=True, to_onehot=2)(i) for i in decollate_batch(val_outputs)]
                    val_labels = [AsDiscrete(to_onehot=2)(i) for i in decollate_batch(val_labels)]

                    dice_metric(y_pred=val_outputs, y=val_labels)

                metric = dice_metric.aggregate().item()
                dice_metric.reset()
                val_time = time.time() - val_start_time

                print(f"Validation at Iter {iteration} | Val Dice: {metric:.4f} | Val Time: {val_time:.2f}s", end="")

                if metric > best_metric:
                    best_metric = metric
                    best_metric_iteration = iteration
                    save_path = os.path.join(model_save_dir, "best_unet3D_model.pth")
                    # torch.save(model.state_dict(), save_path)
                    print(f" -> ğŸ”¥ New Best! ({best_metric:.4f})")
                else:
                    print("")

            # [ä¼˜åŒ–] éªŒè¯åæ¸…ç†æ˜¾å­˜ï¼Œé‡Šæ”¾éªŒè¯é˜¶æ®µçš„å¤§é‡å ç”¨ï¼Œä¸ºæ¥ä¸‹æ¥çš„è®­ç»ƒè…¾å‡ºç©ºé—´
            torch.cuda.empty_cache()

            model.train()
            # é‡ç½®ç»Ÿè®¡
            epoch_loss = 0
            step_in_epoch = 0

    total_time = time.time() - start_time
    print(f"\nè®­ç»ƒç»“æŸã€‚æ€»ç”¨æ—¶: {total_time:.1f}s")
    print(f"æœ€ä½³æ¨¡å‹ Dice: {best_metric:.4f} äº Iteration {best_metric_iteration}")

if __name__ == "__main__":
    parser = get_config_argument_parser(description="UNet3D è®­ç»ƒè„šæœ¬")
    parser.add_argument("--seed", type=int, default=2025, help="éšæœºç§å­ (é»˜è®¤: 2025)")
    args = parser.parse_args()

    # åŠ è½½é…ç½®
    default_config_path = os.path.join(project_root, "configs", "unet3D_train.yaml")
    config_path = args.config if args.config else default_config_path

    config = load_config(config_path, default_config=None)

    if not config:
        print(f"âŒ é”™è¯¯: æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶ {config_path}ï¼Œæˆ–æ–‡ä»¶ä¸ºç©ºï¼")
        sys.exit(1)

    if args.seed != 2025:
        config["seed"] = args.seed
    elif "seed" not in config:
        config["seed"] = 2025

    try:
        train_baseline(config)
    except Exception as e:
        print(f"âŒ è®­ç»ƒå‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
